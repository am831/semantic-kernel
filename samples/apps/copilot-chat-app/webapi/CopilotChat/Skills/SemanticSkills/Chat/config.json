{
  "schema": 1,
  "description": "Generate a chat response from the underlying LLM",
  "type": "completion",
  "completion": {
    "max_tokens": 2048,
    "temperature": 0.7,
    "top_p": 1.0,
    "presence_penalty": 0.5,
    "frequency_penalty": 0.5
  },
  "input": {
    "parameters": [
      {
        "name": "message",
        "description": "The new message",
        "defaultValue": ""
      },
      {
        "name": "chatId",
        "description": "Unique and persistent identifier for the chat",
        "defaultValue": ""
      },
      {
        "name": "userId",
        "description": "Unique and persistent identifier for the user",
        "defaultValue": ""
      },
      {
        "name": "userName",
        "description": "Name of the user",
        "defaultValue": ""
      },
      {
        "name": "proposedPlan",
        "description": "Previously proposed plan that is approved",
        "defaultValue": ""
      },
      {
        "name": "messageType",
        "description": "Type of the message",
        "defaultValue": ""
      },
      {
        "name": "responseMessageId",
        "description": "ID of the response message for planner",
        "defaultValue": ""
      },
      {
        "name": "prompt",
        "description": "The prompt used to generate the response",
        "defaultValue": ""
      },
      {
        "name": "userCancelledPlan",
        "description": "Variable that determines if the user cancelled the plan or not",
        "defaultValue": ""
      },
      {
        "name": "tokenLimit",
        "description": "Maximum number of tokens",
        "defaultValue": ""
      },
      {
        "name": "knowledgeCutoff",
        "description": "LLM knowledge stops at this date",
        "defaultValue": ""
      },
      {
        "name": "Audience",
        "description": "The audience the chat bot is interacting with",
        "defaultValue": ""
      },
      {
        "name": "userIntent",
        "description": "user intent extracted from the conversation history",
        "defaultValue": ""
      },
      {
        "name": "chatContext",
        "description": "Context provided to the LLM by getting as much Chat history as is possible with the remaining token limit",
        "defaultValue": ""
      }
    ]
  }
}